{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open source modeling of rock aggregate resources in Finland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of the Data\n",
    "\n",
    "### 1. Script for unzipping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for unzipping the folders\n",
    "\n",
    "def folderunzip(filename):\n",
    "    import zipfile\n",
    "    \n",
    "    zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "    zip_ref.extractall(\".\")\n",
    "    zip_ref.close()\n",
    "\n",
    "if __name__ == \"__folderunzip__\":\n",
    "    folderunzip()\n",
    "    \n",
    "# execution of the function below\n",
    "#folderunzip(filename = \"M4.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/rawdata/N3.zip\n",
      "./data/rawdata/N4.zip\n",
      "./data/rawdata/M4.zip\n",
      "./data/rawdata/L4.zip\n",
      "./data/rawdata/M3.zip\n",
      "./data/rawdata/N4/N4/N41/N4114R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4112L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4113L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4121R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4131L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4141R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4141L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4131R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4113R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4112R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4121L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4114L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4142R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4132L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4111L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4123R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4122R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4124L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4124R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4111R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4122L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4123L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4132R.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4142L.shp.zip\n",
      "./data/rawdata/N4/N4/N41/N4134L.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4223L.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4211R.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4211L.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4213R.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4212R.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4214L.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4214R.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4212L.shp.zip\n",
      "./data/rawdata/N4/N4/N42/N4213L.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3332L.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3333L.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3344L.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3334R.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3343R.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3342R.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3334L.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3343L.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3333R.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3332R.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3344R.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3341R.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3331R.shp.zip\n",
      "./data/rawdata/N3/N3/N33/N3341L.shp.zip\n",
      "./data/rawdata/N3/N3/N34/N3433R.shp.zip\n",
      "./data/rawdata/N3/N3/N34/N3434R.shp.zip\n",
      "./data/rawdata/N3/N3/N34/N3433L.shp.zip\n",
      "./data/rawdata/N3/N3/N34/N3431R.shp.zip\n"
     ]
    }
   ],
   "source": [
    "#Script for unzipping the datasets\n",
    "import zipfile,fnmatch,os\n",
    "def unzip():\n",
    "    rootPath = r\"./data/rawdata\"\n",
    "\n",
    "    pattern = '*.zip'\n",
    "    \n",
    "    for root, dirs, files in os.walk(rootPath):\n",
    "\n",
    "        for filename in fnmatch.filter(files, pattern):\n",
    "\n",
    "            print(os.path.join(root, filename))\n",
    "\n",
    "            zipfile.ZipFile(os.path.join(root, filename)).extractall(os.path.join(root, filename.split(\".\")[0]))\n",
    "            \n",
    "if __name__ == \"__unzip__\":\n",
    "    unzip()\n",
    "# execution of the function below\n",
    "\n",
    "unzip()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, shutil\n",
    "\n",
    "\n",
    "def deletefiles(directory):\n",
    "    folder = directory\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "if __name__ == \"__deletefiles__\":\n",
    "    deletefiles()\n",
    "    \n",
    "deletefiles(directory = \"data/bufflayers/Merged\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sorting of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/christophbrendel/RockProject\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting script for the NLS Data \n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "fullpath = os.path.join\n",
    "\n",
    "# bufflayers_directory = \"./data/bufflayers\"\n",
    "\n",
    "buildings = \"./data/bufflayers/Buildings\"\n",
    "pipelines = \"./data/bufflayers/Pipelines\"\n",
    "protected = \"./data/bufflayers/Protected\"\n",
    "special = \"./data/bufflayers/Special\"\n",
    "traffic = \"./data/bufflayers/Traffic\"\n",
    "water = \"./data/bufflayers/Water\"\n",
    "warehouse = \"./data/bufflayers/Warehouse\"\n",
    "rawdata_directory = \"./data/rawdata/\"\n",
    "useless_files = \"./data/useless\"\n",
    "\n",
    "# function that sorts the needed layers for buffering and useless layers from our dataset \n",
    "# it's sorting the files based on the description code \n",
    "\n",
    "def main():\n",
    "    for dirname, dirnames, filenames in os.walk(rawdata_directory):\n",
    "        for filename in filenames:\n",
    "            source = fullpath(dirname, filename)\n",
    "            if filename.startswith(\"l_\"):\n",
    "                shutil.move(source, fullpath(traffic, filename))\n",
    "            elif filename.startswith(\"j_\"):\n",
    "                shutil.move(source, fullpath(pipelines, filename))\n",
    "            elif filename.startswith(\"r_\"):\n",
    "                shutil.move(source, fullpath(buildings, filename))\n",
    "            elif filename.startswith(\"s_\"):\n",
    "                shutil.move(source, fullpath(buildings, filename))\n",
    "            elif filename.startswith(\"e_\"):\n",
    "                shutil.move(source, fullpath(special, filename))\n",
    "            elif filename.startswith(\"m_\"):\n",
    "                shutil.move(source, fullpath(water, filename))\n",
    "            elif filename.startswith(\"n_\"):\n",
    "                shutil.move(source, fullpath(warehouse, filename))\n",
    "            elif filename.startswith(\"s_\"):\n",
    "                shutil.move(source, fullpath(protected, filename))          \n",
    "            elif filename.startswith(\"s_\"):\n",
    "                shutil.move(source, fullpath(protected, filename))         \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "# execution of the function below\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the shapefiles\n",
    "def merge():\n",
    "    folder = path.Path(\"./data/bufflayers/Buildings\")\n",
    "    destination = path.Path(\"./data/bufflayers/Merged\")\n",
    "    shapefiles = folder.glob(\"*p.shp\")\n",
    "    gdf = pandas.concat([\n",
    "        gpd.read_file(shp)\n",
    "        for shp in shapefiles\n",
    "    ]).pipe(gpd.GeoDataFrame)\n",
    "    gdf.to_file(destination / 'buildings.shp')\n",
    "    \n",
    "if __name__ == \"__merge__\":\n",
    "    merge()\n",
    "    \n",
    "merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import rasterio.plot\n",
    "import geoplot\n",
    "import rasterio as rio \n",
    "import pathlib as path\n",
    "import pandas \n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources of the merged shapefiles\n",
    "\n",
    "#pipeline_source = \"./data/bufflayers/Merged/pipelines.shp\"\n",
    "#compiled_pipes = gpd.read_file(pipeline_source)\n",
    "\n",
    "buildings_source = \"./data/bufflayers/Merged/buildings.shp\"\n",
    "compiled_buildings = gpd.read_file(buildings_source)\n",
    "\n",
    "#traffic_source = \"./data/bufflayers/Merged/traffic.shp\"\n",
    "#compiled_traffic = gpd.read_file(traffic_source)\n",
    "\n",
    "#water_source = \"./data/bufflayers/Merged/water.shp\"\n",
    "#compiled_water = gpd.read_file(water_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiled_pipes['geometry'] = compiled_pipes.geometry.buffer(5)\n",
    "#compiled_water['geometry'] = compiled_water.geometry.buffer(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compiled_pipes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-29e2e6e006b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#poly = df.geometry.unary_union\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpoints_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_pipes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompiled_pipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#water_clip = compiled_water[compiled_water.geometry.intersects(poly)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compiled_pipes' is not defined"
     ]
    }
   ],
   "source": [
    "#poly = df.geometry.unary_union\n",
    "#points_clip = compiled_pipes[compiled_pipes.geometry.intersects(poly)]\n",
    "\n",
    "#water_clip = compiled_water[compiled_water.geometry.intersects(poly)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "\n",
    "mun = \"./data/Muncipiality/Muncipiality.shp\"\n",
    "#top = \"./data/bufflayers/Pipelines/compiled.shp\"\n",
    "#elev = \"./data/Elevation/M4212.tif\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#elevplot = rio.open(elev)\n",
    "df = gpd.read_file(mun)\n",
    "#df2 = gpd.read_file(top)\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(50,50))\n",
    "\n",
    "# rio.plot.show(elevplot, ax=ax)\n",
    "df.plot(ax=ax,facecolor='none', edgecolor='black')\n",
    "\n",
    "#compiled_pipes.plot(ax=ax, edgecolor=\"orange\")\n",
    "compiled_buildings.plot(ax=ax, edgecolor=\"red\")\n",
    "#compiled_traffic.plot(ax=ax, edgecolor=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
